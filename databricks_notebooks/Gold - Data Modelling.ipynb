{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27f0f4b8-a26e-4064-a51c-47ac59a720a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Gold Layer - Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e4dca8a-8847-4edb-ac5d-0c35543fa663",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1) Create Connection to Azure Storage account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e63baa8c-7165-4b70-9352-f4e14b2a4ffa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storage_account = \"team04sa\"\n",
    "application_id = \"7ab46e7b-cc68-4f3f-9903-9a6bae8e347a\"\n",
    "directory_id = \"b7a954b3-aa07-453e-b8a3-97101aeffcad\"\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", application_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", \"6CO8Q~LRNOBGY5V~1UjmhmTdtEQwcbNbiB6ojcaw\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{directory_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1d58a9d-8d6b-476b-a852-5691bf6c67b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2) Read delta format from Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64c60a97-ddff-4fcf-8932-07d0254a13be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "GOLD_BASE = \"abfss://fooddata@team04sa.dfs.core.windows.net/gold/\"\n",
    "SILVER_PATH = \"abfss://fooddata@team04sa.dfs.core.windows.net/silver/\"\n",
    "\n",
    "silver_df = spark.read.format(\"delta\").load(SILVER_PATH)\n",
    "\n",
    "silver_df.cache()\n",
    "print(\"rows:\", silver_df.count())\n",
    "silver_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c4b3542-c26a-490a-ac65-e11ba903b6e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3) Create DIM Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0f80617-a899-4aeb-8631-07dfa3a2f9c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window\n",
    "\n",
    "# Country\n",
    "dim_country = (silver_df\n",
    "               .select(F.col(\"adm0_id\").alias(\"country_id\"),\n",
    "                       F.col(\"adm0_name\").alias(\"country\"))\n",
    "               .distinct()\n",
    "               .withColumn(\"country_sk\", F.monotonically_increasing_id())\n",
    "               .select(\"country_sk\", \"country_id\", \"country\")\n",
    "               )\n",
    "\n",
    "# Product\n",
    "dim_product = (silver_df\n",
    "               .select(F.col(\"cm_id\").alias(\"product_id\"), \n",
    "                       F.col(\"cm_name\").alias(\"product_name\"),\n",
    "                       F.col(\"cm_group\").alias(\"product_group\"))\n",
    "               .distinct()\n",
    "               .withColumn(\"product_sk\", F.monotonically_increasing_id())\n",
    "               .select(\"product_sk\", \"product_id\", \"product_name\", \"product_group\")\n",
    "               )\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "dim_time = (\n",
    "    silver_df\n",
    "    .select(\"date_month\", \"mp_year\", \"mp_month\", \"year_month\")\n",
    "    .distinct()\n",
    "    # Quartal: floor((month-1)/3)+1  => 1..4\n",
    "    .withColumn(\n",
    "        \"qtr\",\n",
    "        F.concat(\n",
    "            F.lit(\"Q\"),\n",
    "            (F.floor((F.col(\"mp_month\").cast(\"int\") - F.lit(1)) / F.lit(3)) + F.lit(1)).cast(\"string\")\n",
    "        )\n",
    "    )\n",
    "    .withColumnRenamed(\"mp_year\", \"year\")\n",
    "    .withColumnRenamed(\"mp_month\", \"month\")\n",
    "    .withColumnRenamed(\"date_month\", \"date\")\n",
    ")\n",
    "\n",
    "# Unit\n",
    "dim_unit = (silver_df\n",
    "            .select(F.col(\"std_unit_group\"))\n",
    "            .distinct()\n",
    "            .withColumn(\"unit_sk\", F.monotonically_increasing_id())\n",
    "            .select(\"unit_sk\", \"std_unit_group\")\n",
    "            )\n",
    "\n",
    "# Market\n",
    "dim_market = (silver_df\n",
    "              .select(\"mkt_name\",\"mkt_id\").distinct()\n",
    "              .withColumn(\"market_sk\", F.monotonically_increasing_id())\n",
    "              .select(\"market_sk\", \"mkt_name\",\"mkt_id\")\n",
    "              )\n",
    "\n",
    "# Write DIMs\n",
    "(dim_country.write.mode(\"overwrite\").format(\"delta\").save(GOLD_BASE+\"dim_country\"))\n",
    "(dim_product.write.mode(\"overwrite\").format(\"delta\").save(GOLD_BASE+\"dim_product\"))\n",
    "(dim_time.write.mode(\"overwrite\").format(\"delta\").save(GOLD_BASE+\"dim_time\"))\n",
    "(dim_unit.write.mode(\"overwrite\").format(\"delta\").save(GOLD_BASE+\"dim_unit\"))\n",
    "(dim_market.write.mode(\"overwrite\").format(\"delta\").option(\"mergeSchema\", \"true\").save(GOLD_BASE+\"dim_market\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8a0d6a5-b535-4868-a23d-50ea8b1eddd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4) Create Fact table - fact_Food_Price_Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "123914fb-4986-4581-9d5e-096329818bbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------- FACT: Country Difference (KAZ vs AFG) on ProductGroup ----------\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "keys = [\"cm_group\", \"year_month\"]\n",
    "\n",
    "df = silver_df.withColumn(\"adm0_up\", F.upper(F.col(\"adm0_name\")))\n",
    "\n",
    "kaz = (\n",
    "    df.filter(F.col(\"adm0_up\") == \"KAZAKHSTAN\")\n",
    "      .groupBy(*keys)\n",
    "      .agg(\n",
    "          F.avg(\"mp_price_eur\").alias(\"avg_kaz_eur\"),\n",
    "          F.count(\"*\").alias(\"n_kaz\")\n",
    "      )\n",
    ")\n",
    "\n",
    "afg = (\n",
    "    df.filter(F.col(\"adm0_up\") == \"AFGHANISTAN\")\n",
    "      .groupBy(*keys)\n",
    "      .agg(\n",
    "          F.avg(\"mp_price_eur\").alias(\"avg_afg_eur\"),\n",
    "          F.count(\"*\").alias(\"n_afg\")\n",
    "      )\n",
    ")\n",
    "\n",
    "both = (\n",
    "    kaz.join(afg, keys, \"inner\")\n",
    "       .withColumn(\"delta\", F.col(\"avg_kaz_eur\") - F.col(\"avg_afg_eur\"))\n",
    "       .withColumn(\n",
    "           \"delta_pct\",\n",
    "           F.when(F.col(\"avg_afg_eur\") == 0, F.lit(None).cast(\"double\"))\n",
    "            .otherwise(F.col(\"delta\") / F.col(\"avg_afg_eur\"))\n",
    "       )\n",
    ")\n",
    "\n",
    "# Country-IDs aus dim_country (Spalten: country_id, country_sk, country)\n",
    "fcd = (\n",
    "    both.alias(\"p\")\n",
    "    .join(\n",
    "        dim_product.alias(\"dp\"),\n",
    "        F.col(\"p.cm_group\").cast(\"string\") == F.col(\"dp.product_group\").cast(\"string\"),\n",
    "        \"left\"\n",
    "    )\n",
    "    .join(\n",
    "        dim_country.alias(\"dc_kaz\"),\n",
    "        F.upper(F.trim(F.col(\"dc_kaz.country\"))) == F.lit(\"KAZAKHSTAN\"),\n",
    "        \"left\"\n",
    "    )\n",
    "    .join(\n",
    "        dim_country.alias(\"dc_afg\"),\n",
    "        F.upper(F.trim(F.col(\"dc_afg.country\"))) == F.lit(\"AFGHANISTAN\"),\n",
    "        \"left\"\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"p.cm_group\"),\n",
    "        F.col(\"p.year_month\"),\n",
    "        F.col(\"p.avg_kaz_eur\").alias(\"avg_kaz\"),\n",
    "        F.col(\"p.avg_afg_eur\").alias(\"avg_afg\"),\n",
    "        F.col(\"p.delta\"),\n",
    "        F.col(\"p.delta_pct\"),\n",
    "        F.col(\"p.n_kaz\"),\n",
    "        F.col(\"p.n_afg\"),\n",
    "        F.col(\"dp.product_id\").cast(\"string\").alias(\"product_id\"),\n",
    "        F.col(\"dp.product_sk\").alias(\"product_sk\"),\n",
    "        F.col(\"dp.product_name\").alias(\"product_name\"),\n",
    "        F.col(\"dc_kaz.country_id\").alias(\"country_id_kaz\"),\n",
    "        F.col(\"dc_afg.country_id\").alias(\"country_id_afg\")\n",
    "    )\n",
    ")\n",
    "\n",
    "display(fcd)\n",
    "\n",
    "(fcd.write.mode(\"overwrite\").format(\"delta\").option(\"mergeSchema\", \"true\").save(GOLD_BASE+\"fact_Food_Price_Comparison\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold - Data Modelling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
